{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "train = pd.read_csv('data/train.csv') \n",
    "test = pd.read_csv('data/test.csv')\n",
    "ID = test['id']\n",
    "train.drop('id',axis=1,inplace = True)\n",
    "test.drop('id',axis=1,inplace = True) \n",
    "train['n_jobs'].replace(-1,16,inplace=True) \n",
    "test['n_jobs'].replace(-1,16,inplace=True)\n",
    "train.drop('random_state',axis=1,inplace = True)\n",
    "test.drop('random_state',axis=1,inplace = True)\n",
    "train.drop('scale',axis=1,inplace = True)\n",
    "test.drop('scale',axis=1,inplace = True)\n",
    "def fun2(x,y):\n",
    "    if x == 'elasticnet':\n",
    "        return y\n",
    "    elif x == 'l1':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['l1_ratio']= train.apply(lambda x: fun2(x.penalty,x.l1_ratio),axis=1)\n",
    "test['l1_ratio']= test.apply(lambda x: fun2(x.penalty,x.l1_ratio),axis=1)\n",
    "def fun1(x):\n",
    "    y = math.log(x)\n",
    "    return(y)\n",
    "# train['n_samples']= train['n_samples'].apply(lambda x: fun1(x))\n",
    "# test['n_samples']= test['n_samples'].apply(lambda x: fun1(x))\n",
    "# train['n_features']= train['n_features'].apply(lambda x: fun1(x))\n",
    "# test['n_features']= test['n_features'].apply(lambda x: fun1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun4(x,y):\n",
    "    z = x*y\n",
    "    return(z)\n",
    "train['n_cluster']= train.apply(lambda x: fun4(x.n_clusters_per_class,x.n_classes),axis=1)\n",
    "test['n_cluster']= test.apply(lambda x: fun4(x.n_clusters_per_class,x.n_classes),axis=1)\n",
    "def fun5(x,y,z,q):\n",
    "    w = x*y*z/q\n",
    "    return(w)\n",
    "train['total']= train.apply(lambda x: fun5(x.n_samples,x.n_features,x.max_iter,x.n_jobs),axis=1)\n",
    "test['total']= test.apply(lambda x: fun5(x.n_samples,x.n_features,x.max_iter,x.n_jobs),axis=1)\n",
    "train.drop('n_samples',axis=1,inplace = True)\n",
    "test.drop('n_samples',axis=1,inplace = True)\n",
    "train.drop('n_features',axis=1,inplace = True)\n",
    "test.drop('n_features',axis=1,inplace = True)\n",
    "train.drop('max_iter',axis=1,inplace = True)\n",
    "test.drop('max_iter',axis=1,inplace = True)\n",
    "train.drop('n_informative',axis=1,inplace = True)\n",
    "test.drop('n_informative',axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n",
    "train['time'] = train['time'].apply(lambda x: fun1(x))\n",
    "train_Y = train['time']\n",
    "train.drop('time',axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>2.974047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_l2</th>\n",
       "      <td>1.334375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_l1</th>\n",
       "      <td>1.217562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_none</th>\n",
       "      <td>1.094306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>1.003699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>penalty_elasticnet</th>\n",
       "      <td>0.993824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cluster</th>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>0.677777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_ratio</th>\n",
       "      <td>0.491777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_clusters_per_class</th>\n",
       "      <td>0.096758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flip_y</th>\n",
       "      <td>0.071185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_classes</th>\n",
       "      <td>0.047920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Skew\n",
       "total                 2.974047\n",
       "penalty_l2            1.334375\n",
       "penalty_l1            1.217562\n",
       "penalty_none          1.094306\n",
       "n_jobs                1.003699\n",
       "penalty_elasticnet    0.993824\n",
       "n_cluster             0.836670\n",
       "alpha                 0.677777\n",
       "l1_ratio              0.491777\n",
       "n_clusters_per_class  0.096758\n",
       "flip_y                0.071185\n",
       "n_classes             0.047920"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "numeric_feats = train.dtypes[train.dtypes != \"object\"].index\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    train[feat] = boxcox1p(train[feat], lam)\n",
    "    test[feat] = boxcox1p(test[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "mean = train.mean(axis=0)         #normalize features\n",
    "std = train.std(axis=0)\n",
    "train = (train - mean) / std\n",
    "test = (test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1664      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,337\n",
      "Trainable params: 22,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu,\n",
    "                       input_shape=(train.shape[1],)),\n",
    "        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(32, activation=tf.nn.softplus),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    #optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae'])\n",
    "    return model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "# Store training stats\n",
    "history = model.fit(train, train_Y, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(train, train_Y, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test).flatten()\n",
    "submission = pd.DataFrame({'Id': ID,'time': predictions})\n",
    "def fun3(x):\n",
    "    y = math.exp(x)\n",
    "    return(y)\n",
    "submission['time']= submission['time'].apply(lambda x: fun3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./outcome.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.108608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.374393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.421724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.343123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.450041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.543397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.747886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.520563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>13.466209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.337694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5.034742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10.770496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.687265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>26.296959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.456006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.731982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.983567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>7.342912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>3.452115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.076936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.325729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.466913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.618794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.572801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.759741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.434824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.923171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>3.168894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.429790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2.603574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0.371624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.628986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>8.995223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>0.256904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>6.359874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>4.745350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>1.176494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>4.032385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>3.621543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>1.225078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>7.534005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>4.888934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>5.240895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>1.067016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>1.279748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>3.512644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>5.450250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0.389635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>4.909410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>0.897702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>3.800274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>0.749822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>1.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>10.070817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>7.961746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>3.116262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>36.828877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.345313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.152924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id       time\n",
       "0    0   1.108608\n",
       "1    1   9.374393\n",
       "2    2   0.421724\n",
       "3    3   1.343123\n",
       "4    4   2.450041\n",
       "5    5   6.543397\n",
       "6    6   2.747886\n",
       "7    7   0.520563\n",
       "8    8  13.466209\n",
       "9    9   0.337694\n",
       "10  10   5.034742\n",
       "11  11  10.770496\n",
       "12  12   0.687265\n",
       "13  13  26.296959\n",
       "14  14   0.456006\n",
       "15  15   0.731982\n",
       "16  16   0.983567\n",
       "17  17   7.342912\n",
       "18  18   3.452115\n",
       "19  19   1.076936\n",
       "20  20   0.325729\n",
       "21  21   0.466913\n",
       "22  22   0.618794\n",
       "23  23   0.572801\n",
       "24  24   1.759741\n",
       "25  25   1.434824\n",
       "26  26   0.923171\n",
       "27  27   3.168894\n",
       "28  28   1.429790\n",
       "29  29   2.603574\n",
       "..  ..        ...\n",
       "70  70   0.371624\n",
       "71  71   0.628986\n",
       "72  72   8.995223\n",
       "73  73   0.256904\n",
       "74  74   6.359874\n",
       "75  75   4.745350\n",
       "76  76   1.176494\n",
       "77  77   4.032385\n",
       "78  78   3.621543\n",
       "79  79   1.225078\n",
       "80  80   7.534005\n",
       "81  81   4.888934\n",
       "82  82   5.240895\n",
       "83  83   1.067016\n",
       "84  84   1.279748\n",
       "85  85   3.512644\n",
       "86  86   5.450250\n",
       "87  87   0.389635\n",
       "88  88   4.909410\n",
       "89  89   0.897702\n",
       "90  90   3.800274\n",
       "91  91   0.749822\n",
       "92  92   1.356800\n",
       "93  93  10.070817\n",
       "94  94   7.961746\n",
       "95  95   3.116262\n",
       "96  96  36.828877\n",
       "97  97   0.345313\n",
       "98  98   0.708600\n",
       "99  99   0.152924\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
